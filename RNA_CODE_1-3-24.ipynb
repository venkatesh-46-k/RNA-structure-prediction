{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":220},"id":"hOXDHHvcWL94","outputId":"01f0815c-ab42-43e0-f5ea-cc7e35c208d2"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n","/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","\u003cstyle\u003e\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","\u003c/style\u003e\n"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    \u003cdiv\u003e\n","      \u003cprogress value='0' class='' max='32' style='width:300px; height:20px; vertical-align: middle;'\u003e\u003c/progress\u003e\n","      0.00% [0/32 00:00\u0026lt;?]\n","    \u003c/div\u003e\n","    \n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: left;\"\u003e\n","      \u003cth\u003eepoch\u003c/th\u003e\n","      \u003cth\u003etrain_loss\u003c/th\u003e\n","      \u003cth\u003evalid_loss\u003c/th\u003e\n","      \u003cth\u003emae\u003c/th\u003e\n","      \u003cth\u003etime\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\u003cp\u003e\n","\n","    \u003cdiv\u003e\n","      \u003cprogress value='0' class='' max='531' style='width:300px; height:20px; vertical-align: middle;'\u003e\u003c/progress\u003e\n","      0.00% [0/531 00:00\u0026lt;?]\n","    \u003c/div\u003e\n","    "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","import os, gc\n","import numpy as np\n","from sklearn.model_selection import KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","import torch\n","from fastai.vision.all import *\n","def flatten(o):\n","    \"Concatenate all collections and items as a generator\"\n","    for item in o:\n","        if isinstance(o, dict): yield o[item]; continue\n","        elif isinstance(item, str): yield item; continue\n","        try: yield from flatten(item)\n","        except TypeError: yield item\n","\n","from torch.cuda.amp import GradScaler, autocast\n","@delegates(GradScaler)\n","class MixedPrecision(Callback):\n","    \"Mixed precision training using Pytorch's `autocast` and `GradScaler`\"\n","    order = 10\n","    def __init__(self, **kwargs): self.kwargs = kwargs\n","    def before_fit(self):\n","        self.autocast,self.learn.scaler,self.scales = autocast(),GradScaler(**self.kwargs),L()\n","    def before_batch(self): self.autocast.__enter__()\n","    def after_pred(self):\n","        if next(flatten(self.pred)).dtype==torch.float16: self.learn.pred = to_float(self.pred)\n","    def after_loss(self): self.autocast.__exit__(None, None, None)\n","    def before_backward(self): self.learn.loss_grad = self.scaler.scale(self.loss_grad)\n","    def before_step(self):\n","        \"Use `self` as a fake optimizer. `self.skipped` will be set to True `after_step` if gradients overflow. \"\n","        self.skipped=True\n","        self.scaler.step(self)\n","        if self.skipped: raise CancelStepException()\n","        self.scales.append(self.scaler.get_scale())\n","    def after_step(self): self.learn.scaler.update()\n","\n","    @property\n","    def param_groups(self):\n","        \"Pretend to be an optimizer for `GradScaler`\"\n","        return self.opt.param_groups\n","    def step(self, *args, **kwargs):\n","        \"Fake optimizer step to detect whether this batch was skipped from `GradScaler`\"\n","        self.skipped=False\n","    def after_fit(self): self.autocast,self.learn.scaler,self.scales = None,None,None\n","\n","import fastai\n","fastai.callback.fp16.MixedPrecision = MixedPrecision\n","\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","#fname = 'example0'\n","#PATH = '/kaggle/input/stanford-ribonanza-rna-folding-converted/'\n","OUT = './'\n","bs = 256\n","num_workers = 2\n","SEED = 2023\n","nfolds = 4\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","class RNA_Dataset(Dataset):\n","    def __init__(self, df, mode='train', seed=2023, fold=0, nfolds=4,\n","                 mask_only=False, **kwargs):\n","        self.seq_map = {'A':0,'C':1,'G':2,'U':3}\n","        self.Lmax = 206\n","        df['L'] = df.sequence.apply(len)\n","        df_2A3 = df.loc[df.experiment_type=='2A3_MaP']\n","        df_DMS = df.loc[df.experiment_type=='DMS_MaP']\n","\n","        split = list(KFold(n_splits=nfolds, random_state=seed,\n","                shuffle=True).split(df_2A3))[fold][0 if mode=='train' else 1]\n","        df_2A3 = df_2A3.iloc[split].reset_index(drop=True)\n","        df_DMS = df_DMS.iloc[split].reset_index(drop=True)\n","\n","        m = (df_2A3['SN_filter'].values \u003e 0) \u0026 (df_DMS['SN_filter'].values \u003e 0)\n","        df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n","        df_DMS = df_DMS.loc[m].reset_index(drop=True)\n","\n","        self.seq = df_2A3['sequence'].values\n","        self.L = df_2A3['L'].values\n","\n","        self.react_2A3 = df_2A3[[c for c in df_2A3.columns if \\\n","                                 'reactivity_0' in c]].values\n","        self.react_DMS = df_DMS[[c for c in df_DMS.columns if \\\n","                                 'reactivity_0' in c]].values\n","        self.react_err_2A3 = df_2A3[[c for c in df_2A3.columns if \\\n","                                 'reactivity_error_0' in c]].values\n","        self.react_err_DMS = df_DMS[[c for c in df_DMS.columns if \\\n","                                'reactivity_error_0' in c]].values\n","        self.sn_2A3 = df_2A3['signal_to_noise'].values\n","        self.sn_DMS = df_DMS['signal_to_noise'].values\n","        self.mask_only = mask_only\n","\n","    def __len__(self):\n","        return len(self.seq)\n","\n","    def __getitem__(self, idx):\n","        seq = self.seq[idx]\n","        if self.mask_only:\n","            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n","            mask[:len(seq)] = True\n","            return {'mask':mask},{'mask':mask}\n","        seq = [self.seq_map[s] for s in seq]\n","        seq = np.array(seq)\n","        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n","        mask[:len(seq)] = True\n","        seq = np.pad(seq,(0,self.Lmax-len(seq)))\n","\n","        react = torch.from_numpy(np.stack([self.react_2A3[idx],\n","                                           self.react_DMS[idx]],-1))\n","        react_err = torch.from_numpy(np.stack([self.react_err_2A3[idx],\n","                                               self.react_err_DMS[idx]],-1))\n","        sn = torch.FloatTensor([self.sn_2A3[idx],self.sn_DMS[idx]])\n","\n","        return {'seq':torch.from_numpy(seq), 'mask':mask}, \\\n","               {'react':react, 'react_err':react_err,\n","                'sn':sn, 'mask':mask}\n","\n","class LenMatchBatchSampler(torch.utils.data.BatchSampler):\n","    def __iter__(self):\n","        buckets = [[]] * 100\n","        yielded = 0\n","\n","        for idx in self.sampler:\n","            s = self.sampler.data_source[idx]\n","            if isinstance(s,tuple): L = s[0][\"mask\"].sum()\n","            else: L = s[\"mask\"].sum()\n","            L = max(1,L // 16)\n","            if len(buckets[L]) == 0:  buckets[L] = []\n","            buckets[L].append(idx)\n","\n","            if len(buckets[L]) == self.batch_size:\n","                batch = list(buckets[L])\n","                yield batch\n","                yielded += 1\n","                buckets[L] = []\n","\n","        batch = []\n","        leftover = [idx for bucket in buckets for idx in bucket]\n","\n","        for idx in leftover:\n","            batch.append(idx)\n","            if len(batch) == self.batch_size:\n","                yielded += 1\n","                yield batch\n","                batch = []\n","\n","        if len(batch) \u003e 0 and not self.drop_last:\n","            yielded += 1\n","            yield batch\n","\n","def dict_to(x, device='cuda'):\n","    return {k:x[k].to(device) for k in x}\n","\n","def to_device(x, device='cuda'):\n","    return tuple(dict_to(e,device) for e in x)\n","\n","class DeviceDataLoader:\n","    def __init__(self, dataloader, device='cuda'):\n","        self.dataloader = dataloader\n","        self.device = device\n","\n","    def __len__(self):\n","        return len(self.dataloader)\n","\n","    def __iter__(self):\n","        for batch in self.dataloader:\n","            yield tuple(dict_to(x, self.device) for x in batch)\n","\n","class SinusoidalPosEmb(nn.Module):\n","    def __init__(self, dim=16, M=10000):\n","        super().__init__()\n","        self.dim = dim\n","        self.M = M\n","\n","    def forward(self, x):\n","        device = x.device\n","        half_dim = self.dim // 2\n","        emb = math.log(self.M) / half_dim\n","        emb = torch.exp(torch.arange(half_dim, device=device) * (-emb))\n","        emb = x[...,None] * emb[None,...]\n","        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n","        return emb\n","\n","class RNA_Model(nn.Module):\n","    def __init__(self, dim=192, depth=12, head_size=32, **kwargs):\n","        super().__init__()\n","        self.emb = nn.Embedding(4,dim)\n","        self.pos_enc = SinusoidalPosEmb(dim)\n","        self.transformer = nn.TransformerEncoder(\n","            nn.TransformerEncoderLayer(d_model=dim, nhead=dim//head_size, dim_feedforward=4*dim,\n","                dropout=0.1, activation=nn.GELU(), batch_first=True, norm_first=True), depth)\n","        self.proj_out = nn.Linear(dim,2)\n","\n","    def forward(self, x0):\n","        mask = x0['mask']\n","        Lmax = mask.sum(-1).max()\n","        mask = mask[:,:Lmax]\n","        x = x0['seq'][:,:Lmax]\n","\n","        pos = torch.arange(Lmax, device=x.device).unsqueeze(0)\n","        pos = self.pos_enc(pos)\n","        x = self.emb(x)\n","        x = x + pos\n","\n","        x = self.transformer(x, src_key_padding_mask=~mask)\n","        x = self.proj_out(x)\n","\n","        return x\n","\n","def loss(pred,target):\n","    p = pred[target['mask'][:,:pred.shape[1]]]\n","    y = target['react'][target['mask']].clip(0,1)\n","    loss = F.l1_loss(p, y, reduction='none')\n","    loss = loss[~torch.isnan(loss)].mean()\n","\n","    return loss\n","\n","class MAE(Metric):\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.x,self.y = [],[]\n","\n","    def accumulate(self, learn):\n","        x = learn.pred[learn.y['mask'][:,:learn.pred.shape[1]]]\n","        y = learn.y['react'][learn.y['mask']].clip(0,1)\n","        self.x.append(x)\n","        self.y.append(y)\n","\n","    @property\n","    def value(self):\n","        x,y = torch.cat(self.x,0),torch.cat(self.y,0)\n","        loss = F.l1_loss(x, y, reduction='none')\n","        loss = loss[~torch.isnan(loss)].mean()\n","        return loss\n","\n","#df = pd.read_csv(os.path.join(PATH,r'C:\\Users\\VENKATESH\\Downloads\\Data_train.csv'))\n","\n","\n","\n","seed_everything(SEED)\n","os.makedirs(OUT, exist_ok=True)\n","PATH=\"/content/drive/MyDrive/projects_RNA/train_data.parquet\"\n","df=pd.read_parquet(PATH)\n","\n","for fold in [0]: # running multiple folds at kaggle may cause OOM\n","    ds_train = RNA_Dataset(df, mode='train', fold=fold, nfolds=nfolds)\n","    ds_train_len = RNA_Dataset(df, mode='train', fold=fold,\n","                nfolds=nfolds, mask_only=True)\n","    sampler_train = torch.utils.data.RandomSampler(ds_train_len)\n","    len_sampler_train = LenMatchBatchSampler(sampler_train, batch_size=bs,\n","                drop_last=True)\n","    dl_train = DeviceDataLoader(torch.utils.data.DataLoader(ds_train,\n","                batch_sampler=len_sampler_train, num_workers=num_workers,\n","                persistent_workers=True), device)\n","\n","    ds_val = RNA_Dataset(df, mode='eval', fold=fold, nfolds=nfolds)\n","    ds_val_len = RNA_Dataset(df, mode='eval', fold=fold, nfolds=nfolds,\n","               mask_only=True)\n","    sampler_val = torch.utils.data.SequentialSampler(ds_val_len)\n","    len_sampler_val = LenMatchBatchSampler(sampler_val, batch_size=bs,\n","               drop_last=False)\n","    dl_val= DeviceDataLoader(torch.utils.data.DataLoader(ds_val,\n","               batch_sampler=len_sampler_val, num_workers=num_workers), device)\n","    gc.collect()\n","\n","    data = DataLoaders(dl_train,dl_val)\n","    model = RNA_Model()\n","    model = model.to(device)\n","    learn = Learner(data, model, loss_func=loss,cbs=[GradientClip(3.0)],\n","                metrics=[MAE()]).to_fp16()\n","    #fp16 doesn't help at P100 but gives x1.6-1.8 speedup at modern hardware\n","\n","    learn.fit_one_cycle(32, lr_max=5e-4, wd=0.05, pct_start=0.02)\n","    torch.save(learn.model.state_dict(),os.path.join(OUT,f'{fname}_{fold}.pth'))\n","    gc.collect()\n","\n","import gc\n","import os\n","import time\n","import pandas as pd\n","import numpy as np\n","import json\n","import torch\n","from fastai.data.load import DataLoader\n","\n","from datasets import DatasetEightInfer, DatasetTenInfer\n","from models import ModelThirtyNine, ModelThirtyTwo\n","from seed_all import seed_everything\n","\n","SUBMISSION_NUMBER = 27  # the setup is shown in this repository for 27 and 23 only\n","MODEL_EPOCH_NUMBER = 27  # 27 for submission number 27, and 44 for submission number 23\n","# (how many epochs the model was trained, starting from zero)\n","\n","BATCH = 128\n","COL_A = 'reactivity_2A3_MaP'\n","COL_D = 'reactivity_DMS_MaP'\n","\n","\n","def batch_to_csv(output, ids, main_path_for_parquets):\n","    # received a batch of outputs (B, 459, 2) and ids (B, 4) as numpy arrays\n","    name_of_csv = ids[0][0]\n","    dfs = []\n","    for i in range(output.shape[0]):\n","        start_id = ids[i][0]\n","        end_id = ids[i][1]\n","        start_index = ids[i][2]\n","        num_reactivities = ids[i][3]\n","        # Extract relevant reactivities from output[i]\n","        reactivities_a = output[i, start_index: start_index + num_reactivities, 0]\n","        reactivities_d = output[i, start_index: start_index + num_reactivities, 1]\n","        # Create a DataFrame for the current datapoint\n","        datapoint_df = pd.DataFrame({\n","            'id': np.arange(start_id, end_id + 1),\n","            COL_D: reactivities_d,\n","            COL_A: reactivities_a\n","        })\n","        dfs.append(datapoint_df)\n","    small_df = pd.concat(dfs, ignore_index=True)\n","    # the df will be written into .parquet\n","    path = os.path.join(main_path_for_parquets, f\"{name_of_csv}.parquet\")\n","    small_df.to_parquet(path, index=False, engine='pyarrow')\n","    return\n","\n","\n","# before running, folder ../submissions/{SUBMISSION_NUMBER}/all needs to already exist\n","# for submission number 23, it runs for a very long time (eight plus hours) because bpps are not saved\n","# and need to be calculated in dataset\n","if __name__ == '__main__':\n","    seed_everything()\n","    with open('SETTINGS.json') as f:\n","        data = json.load(f)\n","    path_to_test_data = data[\"TEST_DATA\"]\n","    model_dir = data[\"MODEL_DIR\"]\n","    submission_dir = data[\"SUBMISSION_DIR\"]\n","    model_string = f\"{SUBMISSION_NUMBER}/models/model_{MODEL_EPOCH_NUMBER}.pth\"\n","    path_to_model = os.path.join(model_dir, model_string)\n","    main_path_string = f\"{SUBMISSION_NUMBER}/all/\"\n","    main_path_for_parquets = os.path.join(submission_dir, main_path_string)\n","\n","    df = pd.read_parquet(path_to_test_data, engine='pyarrow')\n","    # device\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","    print(device)\n","\n","    if SUBMISSION_NUMBER == 27:\n","        dataset_skeleton = DatasetEightInfer\n","        model_skeleton = ModelThirtyNine\n","        num_workers = 0\n","    elif SUBMISSION_NUMBER == 23:\n","        dataset_skeleton = DatasetTenInfer\n","        model_skeleton = ModelThirtyTwo\n","        num_workers = 40\n","\n","    # dataset and dataloader\n","    dataset = dataset_skeleton(df=df)\n","    loader = DataLoader(dataset=dataset, batch_size=BATCH, pin_memory=False, shuffle=False, device=device,\n","                        num_workers=num_workers)  # num_workers is set to 40 for bpps (submission number 23)\n","\n","    # model\n","    model = model_skeleton()\n","    # load the state dict\n","    model.load_state_dict(torch.load(path_to_model))\n","    model.eval()\n","    model.to(device)\n","\n","    # Start timer\n","    start_time = time.time()\n","    with torch.no_grad():\n","        i = 0\n","        for data, ids in loader:\n","            i += 1\n","            out = model(data)\n","            batch_to_csv(out.detach().cpu().numpy(), ids.detach().cpu().numpy(), main_path_for_parquets)\n","            if i % 50 == 0:\n","                print(f\"step {i}\")\n","    # End timer\n","    end_time = time.time()\n","    # Calculate elapsed time\n","    elapsed_time = end_time - start_time\n","    print(\"Elapsed time: \", elapsed_time)\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zoMm1U-JqxKs"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7CBUbWduqxuR"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15266,"status":"ok","timestamp":1709777696305,"user":{"displayName":"Venkatesh K","userId":"07702989264980855624"},"user_tz":-330},"id":"OP6hTOPWsDRB","outputId":"9df496aa-c75e-48a1-e6e5-e361b354008a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting datasets\n","  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow\u003e=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill\u003c0.3.9,\u003e=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests\u003e=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm\u003e=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]\u003c=2024.2.0,\u003e=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n","Requirement already satisfied: huggingface-hub\u003e=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.3.1)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (23.2.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.4.1)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (6.0.5)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.9.4)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (4.0.3)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.19.4-\u003edatasets) (4.10.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (3.6)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil\u003e=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2023.4)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.8.1-\u003epandas-\u003edatasets) (1.16.0)\n","Installing collected packages: dill, multiprocess, datasets\n","Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16\n"]}],"source":["pip install datasets"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"elapsed":436,"status":"error","timestamp":1711085043641,"user":{"displayName":"Venkatesh K","userId":"07702989264980855624"},"user_tz":-330},"id":"lwNwIx7Eh73n"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'datasets'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-5-6173d5385a27\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 9\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatasetEightInferGeneralization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetTenInferGeneralization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#from seed_all import seed_everything\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import torch\n","from torch.utils.data import DataLoader\n","import json\n","\n","import sklearn.model_selection as model_selection\n","from datasets import DatasetEightInferGeneralization, DatasetTenInferGeneralization\n","from seed_all import seed_everything\n","\n","\n","def load_data(file_path):\n","    return pd.read_parquet(file_path)\n","\n","def load_model(model_dir, submission_number, model_epoch_number):\n","    model_path = os.path.join(model_dir, f\"{submission_number}/models/model_{model_epoch_number}.pth\")\n","    return torch.load(model_path, map_location='cpu')\n","\n","def inference(model, loader):\n","    outputs = []\n","    with torch.no_grad():\n","        for i, (data, _) in enumerate(loader, 1):\n","            output = model(data)\n","            outputs.append(output)\n","            if i % 10 == 0:\n","                print(f\"Step {i}\")\n","    return torch.cat(outputs, dim=0)\n","\n","def visualize_predictions(predictions, submission_number, generalization_dir):\n","    fig, axes = plt.subplots(1, 2, figsize=(10, 5), dpi=500)\n","    titles = ['2A3', 'DMS']\n","    for i in range(2):\n","        axes[i].imshow(predictions[:, :, i], vmin=0, vmax=1, cmap='gray_r')\n","        axes[i].set_title(f'{titles[i]} for {submission_number}')\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(generalization_dir, f\"{submission_number}_test_two.png\"))\n","    plt.close()\n","\n","if __name__ == '__main__':\n","    seed_everything()\n","\n","    with open('SETTINGS.json') as f:\n","        data = json.load(f)\n","    file_to_read = data[\"GENERALIZATION_DATA\"]\n","    model_dir = data[\"MODEL_DIR\"]\n","    generalization_dir = data[\"GENERALIZATION_PICTURES_TWO_DIR\"]\n","\n","    submission_number = 27  # or 23\n","    model_epoch_number = 1 if submission_number == 27 else 44\n","\n","    dataset_class = DatasetEightInferGeneralization if submission_number == 27 else DatasetTenInferGeneralization\n","    model_class = model_selection.ModelThirtyNine if submission_number == 27 else model_selection.ModelThirtyTwo\n","    num_workers = 0 if submission_number == 27 else 40\n","\n","    df = load_data(file_to_read)\n","    dataset = dataset_class(df=df)\n","    loader = DataLoader(dataset=dataset, batch_size=3, pin_memory=False, shuffle=False, num_workers=num_workers)\n","\n","    model = model_class()\n","    model.load_state_dict(load_model(model_dir, submission_number, model_epoch_number))\n","    model.eval()\n","\n","    predictions = inference(model, loader)\n","    print(predictions.shape)\n","\n","    visualize_predictions(predictions, submission_number, generalization_dir)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"im_9uQG5CEoT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"trLiWe1fCErg"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UyyxYxEACEuk"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":110084,"status":"ok","timestamp":1710504369083,"user":{"displayName":"Venkatesh K","userId":"07702989264980855624"},"user_tz":-330},"id":"B7PTmK6WDMyg","outputId":"caa8da5a-ba08-497a-af0c-b8666f6f0b7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting rotary_embedding_torch\n","  Downloading rotary_embedding_torch-0.5.3-py3-none-any.whl (5.3 kB)\n","Collecting beartype (from rotary_embedding_torch)\n","  Downloading beartype-0.17.2-py3-none-any.whl (872 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/872.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m870.4/872.4 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m872.4/872.4 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einops\u003e=0.7 (from rotary_embedding_torch)\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from rotary_embedding_torch) (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003e=2.0-\u003erotary_embedding_torch) (3.13.1)\n","Requirement already satisfied: typing-extensions\u003e=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=2.0-\u003erotary_embedding_torch) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=2.0-\u003erotary_embedding_torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=2.0-\u003erotary_embedding_torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=2.0-\u003erotary_embedding_torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch\u003e=2.0-\u003erotary_embedding_torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch\u003e=2.0-\u003erotary_embedding_torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch\u003e=2.0-\u003erotary_embedding_torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch\u003e=2.0-\u003erotary_embedding_torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch\u003e=2.0-\u003erotary_embedding_torch)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch\u003e=2.0-\u003erotary_embedding_torch)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch\u003e=2.0-\u003erotary_embedding_torch)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch\u003e=2.0-\u003erotary_embedding_torch)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch\u003e=2.0-\u003erotary_embedding_torch)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch\u003e=2.0-\u003erotary_embedding_torch)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch\u003e=2.0-\u003erotary_embedding_torch)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch\u003e=2.0-\u003erotary_embedding_torch)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=2.0-\u003erotary_embedding_torch) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107-\u003etorch\u003e=2.0-\u003erotary_embedding_torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=2.0-\u003erotary_embedding_torch) (2.1.5)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=2.0-\u003erotary_embedding_torch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, einops, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, rotary_embedding_torch\n","Successfully installed beartype-0.17.2 einops-0.7.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 rotary_embedding_torch-0.5.3\n"]}],"source":["!pip install rotary_embedding_torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jypxo96LCFxq"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import math\n","from rotary_embedding_torch import RotaryEmbedding\n","\n","LEN = 457\n","LEN_EOS = 459\n","LEN_FOR_GENERALIZATION = 722\n","\n","############################################################\n","# the code for building transformer (building blocks) is from\n","# https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb\n","\n","# the way how sinusoidal embedding is calculated is from https://www.kaggle.com/code/iafoss/rna-starter-0-186-lb#Model\n","class PosEnc(nn.Module):\n","    \"\"\"\n","    sinusoidal embeddings\n","    \"\"\"\n","    def __init__(self, dim=192, M=10000, num_tokens=LEN_EOS):\n","        super().__init__()\n","        positions = torch.arange(num_tokens).unsqueeze(0)\n","        half_dim = dim // 2\n","        emb = math.log(M) / half_dim\n","        emb = torch.exp(torch.arange(half_dim) * (-emb))\n","        emb = positions[..., None] * emb[None, ...]\n","        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n","        self.pos = emb\n","\n","    def forward(self, x):\n","        device = x.device\n","        pos = self.pos.to(device)\n","        res = x + pos\n","        return res\n","\n","\n","# https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n","\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.d_k = d_model // num_heads\n","\n","        self.W_q = nn.Linear(d_model, d_model)\n","        self.W_k = nn.Linear(d_model, d_model)\n","        self.W_v = nn.Linear(d_model, d_model)\n","        self.W_o = nn.Linear(d_model, d_model)\n","\n","    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n","        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n","        if mask is not None:\n","            _MASKING_VALUE = -1e+30 if attn_scores.dtype == torch.float32 else -1e+4\n","            attn_scores = attn_scores.masked_fill(mask == 0, _MASKING_VALUE)\n","        attn_probs = torch.softmax(attn_scores, dim=-1)\n","        output = torch.matmul(attn_probs, V)\n","        return output\n","\n","    def split_heads(self, x):\n","        batch_size, seq_length, d_model = x.size()\n","        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n","\n","    def combine_heads(self, x):\n","        batch_size, _, seq_length, d_k = x.size()\n","        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n","\n","    def forward(self, Q, K, V, mask=None):\n","        Q = self.split_heads(self.W_q(Q))\n","        K = self.split_heads(self.W_k(K))\n","        V = self.split_heads(self.W_v(V))\n","\n","        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n","        output = self.W_o(self.combine_heads(attn_output))\n","        return output\n","\n","\n","class AttentionRotary(nn.Module):\n","    def __init__(self, d_model, num_heads, rotary_emb):\n","        super(AttentionRotary, self).__init__()\n","        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n","\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.d_k = d_model // num_heads\n","        self.rotary_emb = rotary_emb\n","\n","        self.W_q = nn.Linear(d_model, d_model)\n","        self.W_k = nn.Linear(d_model, d_model)\n","        self.W_v = nn.Linear(d_model, d_model)\n","        self.W_o = nn.Linear(d_model, d_model)\n","\n","    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n","        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n","        if mask is not None:\n","            _MASKING_VALUE = -1e+30 if attn_scores.dtype == torch.float32 else -1e+4\n","            attn_scores = attn_scores.masked_fill(mask == 0, _MASKING_VALUE)\n","        attn_probs = torch.softmax(attn_scores, dim=-1)\n","        output = torch.matmul(attn_probs, V)\n","        return output\n","\n","    def split_heads(self, x):\n","        batch_size, seq_length, d_model = x.size()\n","        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n","\n","    def combine_heads(self, x):\n","        batch_size, _, seq_length, d_k = x.size()\n","        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n","\n","    def forward(self, Q, K, V, mask=None):\n","        Q = self.split_heads(self.W_q(Q))\n","        Q = self.rotary_emb.rotate_queries_or_keys(Q)\n","        K = self.split_heads(self.W_k(K))\n","        K = self.rotary_emb.rotate_queries_or_keys(K)\n","        V = self.split_heads(self.W_v(V))\n","\n","        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n","        output = self.W_o(self.combine_heads(attn_output))\n","        return output\n","\n","\n","class CustomAttentionBPP(nn.Module):\n","    def __init__(self, d_model, num_heads=1):\n","        super(CustomAttentionBPP, self).__init__()\n","        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n","\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.d_k = d_model // num_heads\n","\n","        self.W_v = nn.Linear(d_model, d_model)\n","        self.W_o = nn.Linear(d_model, d_model)\n","\n","    def scaled_dot_product_attention(self, bpp, V, mask=None):\n","        attn_scores = bpp.unsqueeze(1)\n","        _MASKING_VALUE = -1e+30 if attn_scores.dtype == torch.float32 else -1e+4\n","        attn_scores = attn_scores.masked_fill(attn_scores == 0, _MASKING_VALUE)\n","        if mask is not None:\n","            attn_scores = attn_scores.masked_fill(mask == 0, _MASKING_VALUE)\n","        attn_probs = torch.softmax(attn_scores, dim=-1)\n","        output = torch.matmul(attn_probs, V)\n","        return output\n","\n","    def split_heads(self, x):\n","        batch_size, seq_length, d_model = x.size()\n","        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n","\n","    def combine_heads(self, x):\n","        batch_size, _, seq_length, d_k = x.size()\n","        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n","\n","    def forward(self, bpp, V, mask=None):\n","        V = self.split_heads(self.W_v(V))\n","\n","        attn_output = self.scaled_dot_product_attention(bpp, V, mask)\n","        output = self.W_o(self.combine_heads(attn_output))\n","        return output\n","\n","\n","# https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb\n","# gelu is used instead of relu\n","class PositionWiseFeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff):\n","        super(PositionWiseFeedForward, self).__init__()\n","        self.fc1 = nn.Linear(d_model, d_ff)\n","        self.fc2 = nn.Linear(d_ff, d_model)\n","        self.gelu = nn.GELU()\n","\n","    def forward(self, x):\n","        return self.fc2(self.gelu(self.fc1(x)))\n","\n","\n","# https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb\n","# with minor modifications\n","class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout):\n","        super(EncoderLayer, self).__init__()\n","        self.self_attn = MultiHeadAttention(d_model, num_heads)\n","        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask):\n","        attn_output = self.self_attn(x, x, x, mask)\n","        x = self.norm1(x + self.dropout(attn_output))\n","        ff_output = self.feed_forward(x)\n","        x = self.norm2(x + self.dropout(ff_output))\n","        return x\n","\n","\n","class EncoderLayerRotary(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout, rotary_emb):\n","        super(EncoderLayerRotary, self).__init__()\n","        self.self_attn = AttentionRotary(d_model, num_heads, rotary_emb)\n","        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask):\n","        attn_output = self.self_attn(x, x, x, mask)\n","        x = self.norm1(x + self.dropout(attn_output))\n","        ff_output = self.feed_forward(x)\n","        x = self.norm2(x + self.dropout(ff_output))\n","        return x\n","\n","\n","# https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb\n","class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout):\n","        super(DecoderLayer, self).__init__()\n","        self.self_attn = MultiHeadAttention(d_model, num_heads)\n","        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n","        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, enc_output, src_mask, tgt_mask):\n","        attn_output = self.self_attn(x, x, x, tgt_mask)\n","        x = self.norm1(x + self.dropout(attn_output))\n","        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n","        x = self.norm2(x + self.dropout(attn_output))\n","        ff_output = self.feed_forward(x)\n","        x = self.norm3(x + self.dropout(ff_output))\n","        return x\n","\n","\n","class DecoderLayerRotary(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout, rotary_emb):\n","        super(DecoderLayerRotary, self).__init__()\n","        self.self_attn = AttentionRotary(d_model, num_heads, rotary_emb)\n","        self.cross_attn = AttentionRotary(d_model, num_heads, rotary_emb)\n","        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, enc_output, src_mask, tgt_mask):\n","        attn_output = self.self_attn(x, x, x, tgt_mask)\n","        x = self.norm1(x + self.dropout(attn_output))\n","        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n","        x = self.norm2(x + self.dropout(attn_output))\n","        ff_output = self.feed_forward(x)\n","        x = self.norm3(x + self.dropout(ff_output))\n","        return x\n","\n","\n","# similar to DecoderLayer, but as cross_attn, it uses CustomAttentionBPP\n","class DecoderLayerTwo(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout):\n","        super(DecoderLayerTwo, self).__init__()\n","        self.self_attn = MultiHeadAttention(d_model, num_heads)\n","        self.cross_attn = CustomAttentionBPP(d_model)\n","        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, bpp, mask):\n","        attn_output = self.self_attn(x, x, x, mask)\n","        x = self.norm1(x + self.dropout(attn_output))\n","        attn_output = self.cross_attn(bpp=bpp, V=x, mask=mask)\n","        x = self.norm2(x + self.dropout(attn_output))\n","        ff_output = self.feed_forward(x)\n","        x = self.norm3(x + self.dropout(ff_output))\n","        return x\n","\n","#########################################################\n","# models:\n","\n","\n","# first it is decoder layer to use bpp (with sinusoidal pos embeds), then uses rotary embeddings\n","# tgt, info1: seq_inds; info2: bpp; src or info3: struct_inds\n","class ModelThirtyTwo(nn.Module):\n","    def __init__(self, tgt_vocab=7, src_vocab=6, d_model=192, num_heads=6, num_layers=8,\n","                 d_ff=(192*4), dropout=0.1, num_tokens=LEN_EOS):\n","        super(ModelThirtyTwo, self).__init__()\n","        self.tgt_embedding = nn.Embedding(tgt_vocab, d_model)\n","        self.src_embedding = nn.Embedding(src_vocab, d_model)\n","        self.positional_enc = PosEnc(dim=d_model, num_tokens=num_tokens)\n","        self.rotary = RotaryEmbedding(dim=d_model//num_heads)\n","        self.decoder_one = DecoderLayerTwo(d_model, num_heads, d_ff, dropout)\n","        self.decoder = DecoderLayerRotary(d_model, num_heads, d_ff, dropout, self.rotary)\n","        self.encoder_layers = nn.ModuleList([EncoderLayerRotary(d_model, num_heads, d_ff, dropout, self.rotary) for _ in range(num_layers)])\n","        self.fc = nn.Linear(d_model, 2)\n","\n","    def forward(self, data):\n","        tgt = data['info1']\n","        bpp = data['info2']\n","        src = data['info3']\n","        mask = data['mask']\n","\n","        mask = mask.unsqueeze(1).unsqueeze(2)\n","        src = self.src_embedding(src)\n","        tgt = self.positional_enc(self.tgt_embedding(tgt))\n","\n","        output = self.decoder_one(x=tgt, bpp=bpp, mask=mask)\n","\n","        output = self.decoder(x=output, enc_output=src, src_mask=mask, tgt_mask=mask)\n","        for enc_layer in self.encoder_layers:\n","            output = enc_layer(output, mask)\n","\n","        output = self.fc(output)\n","        return output\n","\n","\n","class ModelThirtyNine(nn.Module):\n","    def __init__(self, tgt_vocab=7, src_vocab=6, d_model=384, num_heads=6, num_layers=8, d_ff=384, dropout=0.1):\n","        super(ModelThirtyNine, self).__init__()\n","        self.tgt_embedding = nn.Embedding(tgt_vocab, d_model)\n","        self.src_embedding = nn.Embedding(src_vocab, d_model)\n","        self.positional_enc = RotaryEmbedding(dim=d_model//num_heads)\n","        self.decoder = DecoderLayerRotary(d_model, num_heads, d_ff, dropout, self.positional_enc)\n","        self.encoder_layers = nn.ModuleList([EncoderLayerRotary(d_model, num_heads, d_ff, dropout, self.positional_enc) for _ in range(num_layers)])\n","        self.fc = nn.Linear(d_model, 2)\n","\n","    def forward(self, data):\n","        tgt = data['info1']\n","        src = data['info2']\n","        mask = data['mask']\n","\n","        mask = mask.unsqueeze(1).unsqueeze(2)\n","        tgt = self.tgt_embedding(tgt)\n","        src = self.src_embedding(src)\n","\n","        output = self.decoder(x=tgt, enc_output=src, src_mask=mask, tgt_mask=mask)\n","        for enc_layer in self.encoder_layers:\n","            output = enc_layer(output, mask)\n","\n","        output = self.fc(output)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"elapsed":424,"status":"error","timestamp":1710928422008,"user":{"displayName":"Venkatesh K","userId":"07702989264980855624"},"user_tz":-330},"id":"7eENh4ANKQUS","outputId":"a5dd4cf1-45bb-4996-b8ee-172da44f7c78"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'models'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-2-2edc5674760c\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 7\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mselection\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msome_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mseed_all\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseed_everything\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import torch\n","from torch.utils.data import DataLoader\n","import json\n","from models import selection as model_selection\n","from datasets import some_dataset\n","from seed_all import seed_everything\n","\n","SUBMISSION_NUMBER = 27  # supports only 27 and 23\n","MODEL_EPOCH_NUMBER = 1  # 27 for submission number 27, and 44 for submission number 23\n","BATCH = 3\n","\n","if __name__ == '__main__':\n","    seed_everything()\n","\n","    with open('SETTINGS.json') as f:\n","        data = json.load(f)\n","    file_to_read = data[\"GENERALIZATION_DATA\"]\n","    model_dir = data[\"MODEL_DIR\"]\n","    generalization_dir = data[\"GENERALIZATION_PICTURES_TWO_DIR\"]\n","\n","    model_string = f\"{SUBMISSION_NUMBER}/models/model_{MODEL_EPOCH_NUMBER}.pth\"\n","    model_to_load = os.path.join(model_dir, model_string)\n","\n","    if SUBMISSION_NUMBER == 27:\n","        dataset_skeleton = some_dataset.DatasetEightInferGeneralization\n","        model_skeleton = model_selection.ModelThirtyNine\n","        model = model_skeleton()\n","        num_work = 0\n","    elif SUBMISSION_NUMBER == 23:\n","        dataset_skeleton = some_dataset.DatasetTenInferGeneralization\n","        model_skeleton = model_selection.ModelThirtyTwo\n","        model = model_skeleton(num_tokens=LEN_FOR_GENERALIZATION)\n","        num_work = 40\n","\n","    df = pd.read_parquet(file_to_read)\n","    dataset = dataset_skeleton(df=df)\n","    loader = DataLoader(dataset=dataset, batch_size=BATCH, pin_memory=False, shuffle=False, num_workers=num_work)\n","\n","    state = torch.load(model_to_load, map_location='cpu')\n","    model.load_state_dict(state)\n","    model.eval()\n","\n","    output_main = torch.empty((0, 722, 2))\n","\n","    with torch.no_grad():\n","        for i, (data, ids) in enumerate(loader, 1):\n","            output = model(data)\n","            output_main = torch.cat((output_main, output), 0)\n","\n","            if i % 10 == 0:\n","                print(f\"step {i}\")\n","\n","    m2_preds = output_main[:, 1:-1, :]\n","    print(m2_preds.shape)\n","\n","    fig, axes = plt.subplots(1, 2, dpi=500)\n","\n","    axes[0].imshow(m2_preds[:, :, 0], vmin=0, vmax=1, cmap='gray_r')\n","    axes[0].set_title(f'2A3_for_{SUBMISSION_NUMBER}')\n","\n","    axes[1].imshow(m2_preds[:, :, 1], vmin=0, vmax=1, cmap='gray_r')\n","    axes[1].set_title(f'DMS_for_{SUBMISSION_NUMBER}')\n","\n","    plt.tight_layout()\n","    file_string = f\"{SUBMISSION_NUMBER}_test_two.png\"\n","    path = os.path.join(generalization_dir, file_string)\n","    plt.savefig(path, dpi=500)\n","    plt.close()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uki6x_NXA3M6"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7MvqJQDGA3Qz"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nhO6nWhSAdcj"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPcMT+g8P8TJK5kYrl0sjP6","mount_file_id":"1cygegoLA24yOzNDBywyGDYlsEIWNyouL","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}